import os
import json
import torch
import random
from torch.utils.data import Dataset
from torchvision import transforms
from transformers import CLIPTokenizer
from .baseDataModule import BaseDataModule

from PIL import Image, ImageFile
import warnings

# ğŸ‘‡ å¿½ç•¥"å¤§å›¾åƒ"è­¦å‘Š
warnings.simplefilter('ignore', Image.DecompressionBombWarning)
# ğŸ‘‡ å…è®¸æ— é™å¤§å›¾ç‰‡
Image.MAX_IMAGE_PIXELS = None
# ğŸ‘‡ å¿½ç•¥æˆªæ–­å›¾åƒæŠ¥é”™ï¼ˆé˜²æ­¢æŸåå›¾åƒå¯¼è‡´å´©æºƒï¼‰
ImageFile.LOAD_TRUNCATED_IMAGES = True

GENRE_CLASS = [
    'Drama', 'Comedy', 'Romance', 'Thriller', 'Crime', 'Action', 'Adventure',
    'Horror', 'Documentary', 'Mystery', 'Sci-Fi', 'Fantasy', 'Family',
    'Biography', 'War', 'History', 'Music', 'Animation', 'Musical', 'Western',
    'Sport', 'Short', 'Film-Noir'
]
GENRE_CLASS_DICT = {genre: idx for idx, genre in enumerate(GENRE_CLASS)}


class MMIMDBDataset(Dataset):
    def __init__(self, sample_list, data_dir, image_transform=None, tokenizer=None,
                 max_length=128, missing_strategy="none"):
        self.sample_list = sample_list
        self.data_dir = data_dir
        self.image_transform = image_transform or transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)
        ])
        # # Replace CLIP tokenizer with RoBERTa tokenizer
        # from transformers import RobertaTokenizer
        # self.tokenizer = tokenizer or RobertaTokenizer.from_pretrained("roberta-base")

        self.tokenizer = tokenizer or CLIPTokenizer.from_pretrained("openai/clip-vit-base-patch16")

        self.max_length = max_length
        self.missing_strategy = missing_strategy
        self.missing_prob = 0.7

    def __len__(self):
        return len(self.sample_list)

    def __getitem__(self, idx):
        sample_id = self.sample_list[idx]
        img_path = os.path.join(self.data_dir, "dataset", f"{sample_id}.jpeg")
        json_path = os.path.join(self.data_dir, "dataset", f"{sample_id}.json")

        with open(json_path, "r") as f:
            metadata = json.load(f)

        # 1. æ ‡ç­¾å‘é‡
        label = torch.zeros(len(GENRE_CLASS))
        for genre in metadata["genres"]:
            if genre in GENRE_CLASS_DICT:
                label[GENRE_CLASS_DICT[genre]] = 1.0

        # 2. æ–‡æœ¬å¤„ç†
        plot = metadata["plot"][0] if isinstance(metadata["plot"], list) else metadata["plot"]
        encoded = self.tokenizer(plot, padding="max_length", truncation=True,
                                 max_length=self.max_length, return_tensors="pt")
        # print("input_ids:",encoded["input_ids"].shape,"attention_mask",encoded["input_ids"].shape)
        input_ids = encoded["input_ids"].squeeze(0)
        attention_mask = encoded["attention_mask"].squeeze(0)

        # 3. å›¾åƒå¤„ç†
        image = Image.open(img_path).convert("RGB")
        image = self.image_transform(image)

        # 4. æ¨¡æ€ç¼ºå¤±æ¨¡æ‹Ÿ - å­˜å‚¨åŸå§‹æ•°æ®å¹¶æ ‡è®°ç¼ºå¤±
        missing_type = self._simulate_missing()

        # # ä¿å­˜åŸå§‹æ•°æ®
        # original_image = image.clone()
        # original_input_ids = input_ids.clone()
        # original_attention_mask = attention_mask.clone()

        # æ ‡è®°ç¼ºå¤±æ¨¡æ€ï¼ˆä½†ä¸æ¸…é›¶åŸå§‹æ•°æ®ï¼‰
        # is_image_missing = missing_type in ["image", "both"]
        # is_text_missing = missing_type in ["text", "both"]

        missing_type_tensor = torch.tensor({
                                               "none": 0, "image": 1, "text": 2, "both": 3
                                           }[missing_type])

        return (
            image, input_ids, attention_mask,  # å¯è§æ¨¡æ€æ•°æ®
            label, missing_type_tensor
        )

    def _simulate_missing(self):
        """æ¨¡æ‹Ÿæ¨¡æ€ç¼ºå¤±æƒ…å†µ

        æ ¹æ®è®¾ç½®çš„ç¼ºå¤±ç‡Î·ï¼Œæ¨¡æ‹Ÿä¸åŒç±»å‹çš„æ¨¡æ€ç¼ºå¤±:
        - "none": ä¸æ¨¡æ‹Ÿç¼ºå¤±
        - "both": åŒæ¨¡æ€ç¼ºå¤± (Î·/2å›¾åƒç¼ºå¤±ï¼ŒÎ·/2æ–‡æœ¬ç¼ºå¤±)
        - "image": ä»…å›¾åƒç¼ºå¤± (Î·å›¾åƒç¼ºå¤±)
        - "text": ä»…æ–‡æœ¬ç¼ºå¤± (Î·æ–‡æœ¬ç¼ºå¤±)

        Returns:
            str: ç¼ºå¤±ç±»å‹ï¼Œå¯èƒ½ä¸º "none", "image", "text"
        """
        if self.missing_strategy == "none":
            return "none"

        # ä½¿ç”¨å®ä¾‹å˜é‡çš„ç¼ºå¤±ç‡
        eta = self.missing_prob

        # å¦‚æœæ˜¯floatç±»å‹ï¼Œä½¿ç”¨æŒ‡å®šçš„ç¼ºå¤±ç‡
        if isinstance(self.missing_strategy, float):
            eta = self.missing_strategy

        # æ ¹æ®ç¼ºå¤±ç­–ç•¥æ‰§è¡Œä¸åŒçš„ç¼ºå¤±æ¨¡å¼
        if self.missing_strategy == "both":
            # æŒ‰ç…§è®¾è®¡ï¼šÎ·/2çš„æ¦‚ç‡å›¾åƒç¼ºå¤±ï¼ŒÎ·/2çš„æ¦‚ç‡æ–‡æœ¬ç¼ºå¤±ï¼Œ1-Î·çš„æ¦‚ç‡å®Œæ•´
            return random.choices(
                ["none", "image", "text"],
                weights=[1 - eta, eta / 2, eta / 2],
                k=1
            )[0]
        elif self.missing_strategy == "image":
            # å›¾åƒç¼ºå¤±ï¼šÎ·çš„æ¦‚ç‡å›¾åƒç¼ºå¤±ï¼Œ1-Î·çš„æ¦‚ç‡å®Œæ•´
            return random.choices(
                ["none", "image"],
                weights=[1 - eta, eta],
                k=1
            )[0]
        elif self.missing_strategy == "text":
            # æ–‡æœ¬ç¼ºå¤±ï¼šÎ·çš„æ¦‚ç‡æ–‡æœ¬ç¼ºå¤±ï¼Œ1-Î·çš„æ¦‚ç‡å®Œæ•´
            return random.choices(
                ["none", "text"],
                weights=[1 - eta, eta],
                k=1
            )[0]

        # é»˜è®¤ä¸ç¼ºå¤±
        return "none"

    # Add this method to the MMIMDBDataset class
    def update_missing_prob(self, new_prob):
        """Update the missing probability for this dataset"""
        self.missing_prob = new_prob
        return self

class mmimdbDataModule(BaseDataModule):
    def __init__(self, data_dir="./data/mmimdb", batch_size=32, num_workers=4,
                 image_transform=None, tokenizer=None, max_length=128,
                 missing_strategy="none", missing_prob=0.7,  # æ–°å¢missing_prob
                 val_missing_strategy="none", val_missing_prob=0.0,  # éªŒè¯é›†ä¹Ÿæ”¯æŒ
                 test_missing_strategy="none", test_missing_prob=0.0,  # æ–°å¢æµ‹è¯•é›†é…ç½®
                 image_size=224, patch_size=16,seed=42):
        super().__init__(batch_size, num_workers)

        self.seed = seed

        self.data_dir = data_dir
        self.image_size = image_size
        self.patch_size = patch_size

        if self.image_size % self.patch_size != 0:
            self.image_size = (self.image_size // self.patch_size) * self.patch_size
            print(f"è°ƒæ•´å›¾åƒå°ºå¯¸ä¸º patch_size çš„æ•´æ•°å€: {self.image_size}")

        self.image_transform = image_transform or self.default_transform(self.image_size)
        self.tokenizer = tokenizer
        self.max_length = max_length

        self.missing_strategy = missing_strategy
        self.missing_prob = missing_prob
        self.val_missing_strategy = val_missing_strategy
        self.val_missing_prob = val_missing_prob
        self.test_missing_strategy = test_missing_strategy  # æ–°å¢çš„æµ‹è¯•é›†ç¼ºå¤±ç­–ç•¥
        self.test_missing_prob = test_missing_prob  # æ–°å¢çš„æµ‹è¯•é›†ç¼ºå¤±ç‡

    def setup(self, stage=None):
        split_path = os.path.join(self.data_dir, "split.json")
        with open(split_path, "r") as f:
            split_data = json.load(f)

        random.seed(self.seed)
        random.shuffle(split_data["train"])
        random.shuffle(split_data["dev"])
        random.shuffle(split_data["test"])

        # è®­ç»ƒé›†ç¼ºå¤±ç­–ç•¥
        train_missing = self._parse_missing_strategy(self.missing_strategy, self.missing_prob)

        self.train_dataset = MMIMDBDataset(
            split_data["train"], self.data_dir,
            image_transform=self.image_transform,
            tokenizer=self.tokenizer,
            max_length=self.max_length,
            missing_strategy=train_missing
        )

        # éªŒè¯é›†ç¼ºå¤±ç­–ç•¥
        val_missing = self._parse_missing_strategy(self.val_missing_strategy, self.val_missing_prob)

        self.val_dataset = MMIMDBDataset(
            split_data["dev"], self.data_dir,
            image_transform=self.image_transform,
            tokenizer=self.tokenizer,
            max_length=self.max_length,
            missing_strategy=val_missing
        )
        # æµ‹è¯•é›†ç¼ºå¤±ç­–ç•¥
        test_missing = self._parse_missing_strategy(self.test_missing_strategy, self.test_missing_prob)

        self.test_dataset = MMIMDBDataset(
            split_data["test"], self.data_dir,
            image_transform=self.image_transform,
            tokenizer=self.tokenizer,
            max_length=self.max_length,
            missing_strategy=test_missing
        )


    def _parse_missing_strategy(self, strategy, prob):
        """è§£æç¼ºå¤±ç­–ç•¥ã€‚"""
        if strategy == "random":
            return prob  # randomå°±è¿”å›ç¼ºå¤±ç‡
        elif strategy in ["both", "image", "text"]:
            return strategy
        else:
            return "none"

    def _build_dataset(self, split):
        pass  # æœªä½¿ç”¨



    def default_transform(self, image_size):
        return transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)
        ])

    def get_class_weights(self):
        """
        è¿”å›æ¯ä¸ªç±»åˆ«çš„åŠ æƒ BCE æƒé‡ï¼Œå€¼ä¸º max_count / class_countã€‚
        å¯ç”¨äº pos_weight å‚æ•°ã€‚
        """
        class_counts = torch.tensor([
            13967, 8592, 5364, 5192, 3838, 3550, 2710, 2703, 2082, 2057,
            1991, 1933, 1668, 1343, 1335, 1143, 1045, 997, 841, 705,
            634, 471, 338
        ], dtype=torch.float32)
        max_count = class_counts.max()
        weights = max_count / class_counts
        return weights

    def get_num_classes(self):
        return 23

